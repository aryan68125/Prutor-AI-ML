{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd3cfc5e",
   "metadata": {},
   "source": [
    "# CountVectorizer is a Transformer that is used to Transform text sentences into numbers that can later be fed in Logistic regression or any other Machine learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05e9d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re #re here is the regex module of python\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5f09422",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Restaurant_Reviews.tsv', sep='\\t') # define seprator as \\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "879cb287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab6ccad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "213836e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "Name: Liked, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Liked.value_counts() ## Cheking the number of liked and disliked reviews in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d9f1db1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    s = re.sub('<*?>',' ', x) #removes all html tags\n",
    "    \n",
    "#     s = re.sub(\"wasn't\", 'was not',s) #removes wasn't to was not\n",
    "#     s = re.sub(\"don't\", 'do not',s)\n",
    "#     s = re.sub(\"din't\", 'did not',s)\n",
    "#     s = re.sub(\"wouldn't\", 'would not',s)\n",
    "#     s = re.sub(\"won't\", 'will not',s)\n",
    "#     s = re.sub(\"isn't\", 'is not',s)\n",
    "#     s = re.sub(\"needn't\", 'need not',s)\n",
    "#     s = re.sub(\"hasn't\", 'has not',s)\n",
    "    \n",
    "    s = re.sub('[^A-Za-z]',' ',s) #removes everything else except for a to z and A to Z\n",
    "    s = re.sub('\\s+',' ',s) #removes more than one spaces\n",
    "    s = s.strip() #removes spaces from the beginning and ending of the sentences\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "31f6cabc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the food wasn t bad'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(\"The Food wasn't bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "78b486e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df.Review.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "4f459153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow loved this place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust is not good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>i think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>appetite instantly gone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>overall i was not impressed and would not go back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>the whole experience was underwhelming and i t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>then as if i hadn t wasted enough of my life t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                                 wow loved this place      1\n",
       "1                                    crust is not good      0\n",
       "2             not tasty and the texture was just nasty      0\n",
       "3    stopped by during the late may bank holiday of...      1\n",
       "4    the selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  i think food should have flavor and texture an...      0\n",
       "996                            appetite instantly gone      0\n",
       "997  overall i was not impressed and would not go back      0\n",
       "998  the whole experience was underwhelming and i t...      0\n",
       "999  then as if i hadn t wasted enough of my life t...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2b797791",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.Review.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "ab23a701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a6744d7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "7b9d11e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Liked.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4f70f689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "69132a6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7901c69a",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a1f4508b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "43148682",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 0.20,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8267ebc",
   "metadata": {},
   "source": [
    "## Now Apply CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b1e18638",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/Machine_learning/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords') #Run this command to download and install Stopwords from natural language processor\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ed3d861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "f1fadfff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i,me,my,myself,we,our,ours,ourselves,you,you're,you've,you'll,you'd,your,yours,yourself,yourselves,he,him,his,himself,she,she's,her,hers,herself,it,it's,its,itself,they,them,their,theirs,themselves,what,which,who,whom,this,that,that'll,these,those,am,is,are,was,were,be,been,being,have,has,had,having,do,does,did,doing,a,an,the,and,but,if,or,because,as,until,while,of,at,by,for,with,about,against,between,into,through,during,before,after,above,below,to,from,up,down,in,out,on,off,over,under,again,further,then,once,here,there,when,where,why,how,all,any,both,each,few,more,most,other,some,such,no,nor,not,only,own,same,so,than,too,very,s,t,can,will,just,don,don't,should,should've,now,d,ll,m,o,re,ve,y,ain,aren,aren't,couldn,couldn't,didn,didn't,doesn,doesn't,hadn,hadn't,hasn,hasn't,haven,haven't,isn,isn't,ma,mightn,mightn't,mustn,mustn't,needn,needn't,shan,shan't,shouldn,shouldn't,wasn,wasn't,weren,weren't,won,won't,wouldn,wouldn't,"
     ]
    }
   ],
   "source": [
    "# getting stopwords from nltk \n",
    "for i in list(words):\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "651b73ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no is present\n",
      "not is present\n",
      "don't is present\n",
      "wouldn't is present\n",
      "won't is present\n",
      "wasn't is present\n",
      "isn't is present\n",
      "needn't is present\n",
      "hasn't is present\n"
     ]
    }
   ],
   "source": [
    "#checking if now, no, don't , do not , not are present or not\n",
    "if 'no' in words:\n",
    "    print(\"no is present\")\n",
    "if 'not' in words:\n",
    "    print(\"not is present\")\n",
    "if 'never' in words:\n",
    "    print(\"never is present\")\n",
    "if \"don't\" in words:\n",
    "    print(\"don't is present\")\n",
    "if 'do not' in words:\n",
    "    print(\"do not is present\")\n",
    "if \"din't\" in words:\n",
    "    print(\"din't is present\")\n",
    "if 'did not' in words:\n",
    "    print(\"did not is present\")\n",
    "if \"wouldn't\" in words:\n",
    "    print(\"wouldn't is present\")\n",
    "if 'would not' in words:\n",
    "    print(\"would not is present\")\n",
    "if 'will not' in words:\n",
    "    print(\"will not is present\")\n",
    "if \"won't\" in words:\n",
    "    print(\"won't is present\")\n",
    "if \"wasn't\" in words:\n",
    "    print(\"wasn't is present\")\n",
    "if \"isn't\" in words:\n",
    "    print(\"isn't is present\")\n",
    "if \"needn't\" in words:\n",
    "    print(\"needn't is present\")\n",
    "if \"hasn't\" in words:\n",
    "    print(\"hasn't is present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7406b3",
   "metadata": {},
   "source": [
    "## now we have to make sure that all the negative words are removed from 'words = stopwords.words('english')' before we feed it to 'count_vectorizer = CountVectorizer(stop_words=words)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "13348781",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removinf all the negative words from the \"words\" variable\n",
    "negative_words = ['no','not','never', \"don't\", \"do not\", \"din't\", \"did not\", \"wouldn't\", \"would not\"]\n",
    "if 'no' in words:\n",
    "    words.remove(\"no\")\n",
    "if 'not' in words:\n",
    "    words.remove(\"not\")\n",
    "if 'never' in words:\n",
    "    words.remove(\"never\")\n",
    "if \"don't\" in words:\n",
    "    words.remove(\"don't\")\n",
    "if 'do not' in words:\n",
    "    words.remove(\"do not\")\n",
    "if \"din't\" in words:\n",
    "    words.remove(\"din't\")\n",
    "if 'did not' in words:\n",
    "    words.remove(\"did not\")\n",
    "if \"wouldn't\" in words:\n",
    "    words.remove(\"wouldn't\")\n",
    "if 'would not' in words:\n",
    "    words.remove(\"would not\")\n",
    "if 'will not' in words:\n",
    "    words.remove(\"will not\")\n",
    "if \"won't\" in words:\n",
    "    words.remove(\"won't\")\n",
    "if \"wasn't\" in words:\n",
    "    words.remove(\"wasn't\")\n",
    "if \"isn't\" in words:\n",
    "    words.remove(\"isn't\")\n",
    "if \"needn't\" in words:\n",
    "    words.remove(\"needn't\")\n",
    "if \"hasn't\" in words:\n",
    "    words.remove(\"hasn't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "446e6f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no negative words are present\n"
     ]
    }
   ],
   "source": [
    "#again rechecking if negative words are present or not \n",
    "negative_words = ['no','not','never', \"don't\", \"do not\", \"din't\", \"did not\", \"wouldn't\", \"would not\"]\n",
    "if 'no' in words:\n",
    "    print(\"no is present\")\n",
    "if 'not' in words:\n",
    "    print(\"not is present\")\n",
    "if 'never' in words:\n",
    "    print(\"never is present\")\n",
    "if \"don't\" in words:\n",
    "    print(\"don't is present\")\n",
    "if 'do not' in words:\n",
    "    print(\"do not is present\")\n",
    "if \"din't\" in words:\n",
    "    print(\"din't is present\")\n",
    "if 'did not' in words:\n",
    "    print(\"did not is present\")\n",
    "if \"wouldn't\" in words:\n",
    "    print(\"wouldn't is present\")\n",
    "if 'would not' in words:\n",
    "    print(\"would not is present\")\n",
    "if 'will not' in words:\n",
    "    print(\"will not is present\")\n",
    "if \"won't\" in words:\n",
    "    print(\"won't is present\")\n",
    "if \"wasn't\" in words:\n",
    "    print(\"wasn't is present\")\n",
    "if \"isn't\" in words:\n",
    "    print(\"isn't is present\")\n",
    "if \"needn't\" in words:\n",
    "    print(\"needn't is present\")\n",
    "if \"hasn't\" in words:\n",
    "    print(\"hasn't is present\")\n",
    "else:\n",
    "    print(\"no negative words are present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f05927ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=words) #initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "336431d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = count_vectorizer.fit_transform(xtrain)\n",
    "cv_test = count_vectorizer.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "dd9672d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1653)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "238325dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "ce9f74c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1653)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "5ea9edb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2380b42a",
   "metadata": {},
   "source": [
    "## Now we can apply Logistic Regression Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "7c5f3ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "898d6fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "log = LogisticRegression() #initializing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "d961b963",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.fit(cv_train,ytrain) #training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "c9013bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = log.score(cv_test,ytest) # scoring model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4fb1652c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.825"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "88167c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = log.predict(cv_test) #predicting \n",
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244994dd",
   "metadata": {},
   "source": [
    "## Printing number of misspredicted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "621de853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  4,   6,  27,  32,  35,  36,  37,  60,  63,  65,  67,  72,  76,\n",
      "        83,  86,  92, 100, 101, 115, 121, 122, 125, 134, 135, 137, 138,\n",
      "       145, 155, 157, 163, 167, 169, 173, 176, 180]),)\n"
     ]
    }
   ],
   "source": [
    "print(np.where(ytest!=pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ce5f85",
   "metadata": {},
   "source": [
    "## Testing the trained model on a custom input from the user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "b1478edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"I wouldn't have eaten the food if I had known\", \n",
    "        \"I won't eat here ever again\", \n",
    "        \"The food was good\", \n",
    "        \"It was a good meal\",\n",
    "       \"The food was not upto the mark like it used to in previous years\", \n",
    "        \"I should not have ordered these. It's bad...It's really bad\",\n",
    "       \"Awesome Food !!!...Good service\", \n",
    "        \"I am satisfied with the food\",\n",
    "       \"They needn't have to make the order process so complicated\",\n",
    "       \"They din't have to go above and beyond but they did it was cool.....I loved it\",\n",
    "       \"The meal wasn't satisfactory\",\n",
    "       \"The food was bad\"]\n",
    "clean_data = []\n",
    "for k in test:\n",
    "    clean_data.append(clean(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "6c6e1284",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = count_vectorizer.transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "95744430",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 1653)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "93f5bb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "776e2bc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.predict(test1) # 0 means negative review and 1 means positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "f76c24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"I am satisfied with the food \" should be a positive review but it's classifying it as a negative one [pos = 7]\n",
    "# how to solve this issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a6d7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f3bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945372ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c6da9d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

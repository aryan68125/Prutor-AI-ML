{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4212fba",
   "metadata": {},
   "source": [
    "# Naive Bayes Algotitem is  only used when we want to work with text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "21331347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/Machine_learning/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re #re here is the regex module of python\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords') #Run this command to download and install Stopwords from natural language processor\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "1b97b270",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Restaurant_Reviews.tsv', sep='\\t') # define seprator as \\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "976a3cdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                             Wow... Loved this place.      1\n",
       "1                                   Crust is not good.      0\n",
       "2            Not tasty and the texture was just nasty.      0\n",
       "3    Stopped by during the late May bank holiday of...      1\n",
       "4    The selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  I think food should have flavor and texture an...      0\n",
       "996                           Appetite instantly gone.      0\n",
       "997  Overall I was not impressed and would not go b...      0\n",
       "998  The whole experience was underwhelming, and I ...      0\n",
       "999  Then, as if I hadn't wasted enough of my life ...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "bda710c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "8bc4e1a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    500\n",
       "1    500\n",
       "Name: Liked, dtype: int64"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Liked.value_counts() ## Cheking the number of liked and disliked reviews in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "404d5105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    s = re.sub('<*?>',' ', x) #removes all html tags\n",
    "    \n",
    "    s = re.sub(\"wasn't\", 'was not',s) #removes wasn't to was not\n",
    "    s = re.sub(\"don't\", 'do not',s)\n",
    "    s = re.sub(\"din't\", 'did not',s)\n",
    "    s = re.sub(\"wouldn't\", 'would not',s)\n",
    "    s = re.sub(\"won't\", 'will not',s)\n",
    "    s = re.sub(\"isn't\", 'is not',s)\n",
    "    s = re.sub(\"needn't\", 'need not',s)\n",
    "    s = re.sub(\"hasn't\", 'has not',s)\n",
    "    \n",
    "    s = re.sub('[^A-Za-z]',' ',s) #removes everything else except for a to z and A to Z\n",
    "    s = re.sub('\\s+',' ',s) #removes more than one spaces\n",
    "    s = s.strip() #removes spaces from the beginning and ending of the sentences\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "be909d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Review'] = df.Review.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "5e2d5f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wow loved this place</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>crust is not good</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>not tasty and the texture was just nasty</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>stopped by during the late may bank holiday of...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the selection on the menu was great and so wer...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>i think food should have flavor and texture an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>appetite instantly gone</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>overall i was not impressed and would not go back</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>the whole experience was underwhelming and i t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>then as if i hadn t wasted enough of my life t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Review  Liked\n",
       "0                                 wow loved this place      1\n",
       "1                                    crust is not good      0\n",
       "2             not tasty and the texture was just nasty      0\n",
       "3    stopped by during the late may bank holiday of...      1\n",
       "4    the selection on the menu was great and so wer...      1\n",
       "..                                                 ...    ...\n",
       "995  i think food should have flavor and texture an...      0\n",
       "996                            appetite instantly gone      0\n",
       "997  overall i was not impressed and would not go back      0\n",
       "998  the whole experience was underwhelming and i t...      0\n",
       "999  then as if i hadn t wasted enough of my life t...      0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "87f0b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.Review.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "897fb2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "880755f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "de7c53c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Liked.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "d28e766c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "6ea13a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725d9141",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "24e9521d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 0.20,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6edddbbd",
   "metadata": {},
   "source": [
    "## Now Apply CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c473bd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "20d6337e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i,me,my,myself,we,our,ours,ourselves,you,you're,you've,you'll,you'd,your,yours,yourself,yourselves,he,him,his,himself,she,she's,her,hers,herself,it,it's,its,itself,they,them,their,theirs,themselves,what,which,who,whom,this,that,that'll,these,those,am,is,are,was,were,be,been,being,have,has,had,having,do,does,did,doing,a,an,the,and,but,if,or,because,as,until,while,of,at,by,for,with,about,against,between,into,through,during,before,after,above,below,to,from,up,down,in,out,on,off,over,under,again,further,then,once,here,there,when,where,why,how,all,any,both,each,few,more,most,other,some,such,no,nor,not,only,own,same,so,than,too,very,s,t,can,will,just,don,don't,should,should've,now,d,ll,m,o,re,ve,y,ain,aren,aren't,couldn,couldn't,didn,didn't,doesn,doesn't,hadn,hadn't,hasn,hasn't,haven,haven't,isn,isn't,ma,mightn,mightn't,mustn,mustn't,needn,needn't,shan,shan't,shouldn,shouldn't,wasn,wasn't,weren,weren't,won,won't,wouldn,wouldn't,"
     ]
    }
   ],
   "source": [
    "# getting stopwords from nltk \n",
    "for i in list(words):\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "447d8db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no is present\n",
      "not is present\n",
      "don't is present\n",
      "wouldn't is present\n",
      "won't is present\n",
      "wasn't is present\n",
      "isn't is present\n",
      "needn't is present\n",
      "hasn't is present\n"
     ]
    }
   ],
   "source": [
    "#checking if now, no, don't , do not , not are present or not\n",
    "if 'no' in words:\n",
    "    print(\"no is present\")\n",
    "if 'not' in words:\n",
    "    print(\"not is present\")\n",
    "if 'never' in words:\n",
    "    print(\"never is present\")\n",
    "if \"don't\" in words:\n",
    "    print(\"don't is present\")\n",
    "if 'do not' in words:\n",
    "    print(\"do not is present\")\n",
    "if \"din't\" in words:\n",
    "    print(\"din't is present\")\n",
    "if 'did not' in words:\n",
    "    print(\"did not is present\")\n",
    "if \"wouldn't\" in words:\n",
    "    print(\"wouldn't is present\")\n",
    "if 'would not' in words:\n",
    "    print(\"would not is present\")\n",
    "if 'will not' in words:\n",
    "    print(\"will not is present\")\n",
    "if \"won't\" in words:\n",
    "    print(\"won't is present\")\n",
    "if \"wasn't\" in words:\n",
    "    print(\"wasn't is present\")\n",
    "if \"isn't\" in words:\n",
    "    print(\"isn't is present\")\n",
    "if \"needn't\" in words:\n",
    "    print(\"needn't is present\")\n",
    "if \"hasn't\" in words:\n",
    "    print(\"hasn't is present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e42703",
   "metadata": {},
   "source": [
    "## now we have to make sure that all the negative words are removed from 'words = stopwords.words('english')' before we feed it to 'count_vectorizer = CountVectorizer(stop_words=words)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "5724910b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removinf all the negative words from the \"words\" variable\n",
    "negative_words = ['no','not','never', \"don't\", \"do not\", \"din't\", \"did not\", \"wouldn't\", \"would not\"]\n",
    "if 'no' in words:\n",
    "    words.remove(\"no\")\n",
    "if 'not' in words:\n",
    "    words.remove(\"not\")\n",
    "if 'never' in words:\n",
    "    words.remove(\"never\")\n",
    "# if \"don't\" in words:\n",
    "#     words.remove(\"don't\")\n",
    "# if 'do not' in words:\n",
    "#     words.remove(\"do not\")\n",
    "# if \"din't\" in words:\n",
    "#     words.remove(\"din't\")\n",
    "# if 'did not' in words:\n",
    "#     words.remove(\"did not\")\n",
    "# if \"wouldn't\" in words:\n",
    "#     words.remove(\"wouldn't\")\n",
    "# if 'would not' in words:\n",
    "#     words.remove(\"would not\")\n",
    "# if 'will not' in words:\n",
    "#     words.remove(\"will not\")\n",
    "# if \"won't\" in words:\n",
    "#     words.remove(\"won't\")\n",
    "# if \"wasn't\" in words:\n",
    "#     words.remove(\"wasn't\")\n",
    "# if \"isn't\" in words:\n",
    "#     words.remove(\"isn't\")\n",
    "# if \"needn't\" in words:\n",
    "#     words.remove(\"needn't\")\n",
    "# if \"hasn't\" in words:\n",
    "#     words.remove(\"hasn't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "9bece7a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "don't is present\n",
      "wouldn't is present\n",
      "won't is present\n",
      "wasn't is present\n",
      "isn't is present\n",
      "needn't is present\n",
      "hasn't is present\n"
     ]
    }
   ],
   "source": [
    "#again rechecking if negative words are present or not \n",
    "negative_words = ['no','not','never', \"don't\", \"do not\", \"din't\", \"did not\", \"wouldn't\", \"would not\"]\n",
    "if 'no' in words:\n",
    "    print(\"no is present\")\n",
    "if 'not' in words:\n",
    "    print(\"not is present\")\n",
    "if 'never' in words:\n",
    "    print(\"never is present\")\n",
    "if \"don't\" in words:\n",
    "    print(\"don't is present\")\n",
    "if 'do not' in words:\n",
    "    print(\"do not is present\")\n",
    "if \"din't\" in words:\n",
    "    print(\"din't is present\")\n",
    "if 'did not' in words:\n",
    "    print(\"did not is present\")\n",
    "if \"wouldn't\" in words:\n",
    "    print(\"wouldn't is present\")\n",
    "if 'would not' in words:\n",
    "    print(\"would not is present\")\n",
    "if 'will not' in words:\n",
    "    print(\"will not is present\")\n",
    "if \"won't\" in words:\n",
    "    print(\"won't is present\")\n",
    "if \"wasn't\" in words:\n",
    "    print(\"wasn't is present\")\n",
    "if \"isn't\" in words:\n",
    "    print(\"isn't is present\")\n",
    "if \"needn't\" in words:\n",
    "    print(\"needn't is present\")\n",
    "if \"hasn't\" in words:\n",
    "    print(\"hasn't is present\")\n",
    "else:\n",
    "    print(\"no negative words are present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d5d567",
   "metadata": {},
   "source": [
    "## How to use lemmantizer in CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "6d270857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## creating a custom function that will return a root of the words in a sentence\n",
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "# from nltk.stem import WordNetLemmatizer\n",
    "  \n",
    "# lemmatizer = WordNetLemmatizer() # initializing lammentizer\n",
    "# analyzer = CountVectorizer().build_analyzer() # building counVectorizer analyzer\n",
    "# def lemmant_words(doc):\n",
    "#     return (lemmatizer.lemmatize(w) for w in analyzer(doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "bad54944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count_vectorizer = CountVectorizer(stop_words=words,analyzer=lemmant_words) #initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307090ed",
   "metadata": {},
   "source": [
    "## countvectorizer whithout lemmentization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "cebb2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "bc2e4ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = count_vectorizer.fit_transform(xtrain) # transforming data from text to integers\n",
    "cv_test = count_vectorizer.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "c508dabe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 1653)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "2422a7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "f38d2785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1653)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "98a619c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab36f02c",
   "metadata": {},
   "source": [
    "## Now we can apply Naive Bayes Algotitem Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "dacff25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "6c237d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB() #initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "ec9b16e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(cv_train,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "f65827ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = nb.score(cv_test,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "f68228a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.77\n"
     ]
    }
   ],
   "source": [
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "ea760519",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9525"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(cv_train,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "c97a7d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use logistic regression, svm, tfidf(mindf ,maxdf, max features, n_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b5a0c",
   "metadata": {},
   "source": [
    "## Evaluating model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "5b144be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"I wouldn't have eaten the food if I had known\", \n",
    "        \"I won't eat here ever again\",\n",
    "        \"crust is not good\",\n",
    "        \"The food was good\", \n",
    "        \"It was a good meal\",\n",
    "       \"The food was not upto the mark like it used to in previous years\", \n",
    "        \"I should not have ordered these. It's bad...It's really bad\",\n",
    "       \"Awesome Food !!!...Good service\", \n",
    "        \"I am satisfied with the food\",\n",
    "       \"They needn't have to make the order process so complicated\",\n",
    "       \"They din't have to go above and beyond but they did it was cool.....I loved it\",\n",
    "       \"The meal wasn't satisfactory\",\n",
    "       \"The food was bad\"]\n",
    "clean_data = []\n",
    "for k in test:\n",
    "    clean_data.append(clean(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "9e6f3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = count_vectorizer.transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "28f1b0c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(test1) # 0 means negative review and 1 means positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "461d67d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  \"They din't have to go above and beyond but they did it was cool.....I loved it\", \n",
    "# was predicted correctly in this model\n",
    "# In this model also \"\"I am satisfied with the food\"\" was predicted incorrectly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3063480",
   "metadata": {},
   "source": [
    "# Example 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "id": "3aaec403",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Detect spam and ham email messages using naive bayes algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "4d343499",
   "metadata": {},
   "outputs": [],
   "source": [
    "#spam_ham_dataset.csv\n",
    "df2 = pd.read_csv('spam_ham_dataset.csv', sep=',') # define seprator as ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "b485ce2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: put the 10 on the ft\\r\\nthe transport...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: 3 / 4 / 2000 and following noms\\r\\nhp...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: calpine daily gas nomination\\r\\n&gt;\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: industrial worksheets for august 2000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: important online banking alert\\r\\ndea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "5c1bf2b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 4)"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "569961b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    s = re.sub('<*?>',' ', x) #removes all html tags\n",
    "    \n",
    "    s = re.sub(\"wasn't\", 'was not',s) #removes wasn't to was not\n",
    "    s = re.sub(\"don't\", 'do not',s)\n",
    "    s = re.sub(\"din't\", 'did not',s)\n",
    "    s = re.sub(\"wouldn't\", 'would not',s)\n",
    "    s = re.sub(\"won't\", 'will not',s)\n",
    "    s = re.sub(\"isn't\", 'is not',s)\n",
    "    s = re.sub(\"needn't\", 'need not',s)\n",
    "    s = re.sub(\"hasn't\", 'has not',s)\n",
    "    s = re.sub(\"shan't\",'shall not',s)\n",
    "    \n",
    "    s = re.sub('[^A-Za-z]',' ',s) #removes everything else except for a to z and A to Z\n",
    "    s = re.sub('\\s+',' ',s) #removes more than one spaces\n",
    "    s = s.strip() #removes spaces from the beginning and ending of the sentences\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "4c16d7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['text'] = df2.text.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "b4b6bfe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject enron methanol meter this is a follow ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject hpl nom for january see attached file ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject neon retreat ho ho ho we re around to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>subject photoshop windows office cheap main tr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject re indian springs this deal is to book...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5166</th>\n",
       "      <td>1518</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject put the on the ft the transport volume...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5167</th>\n",
       "      <td>404</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject and following noms hpl can t take the ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5168</th>\n",
       "      <td>2933</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject calpine daily gas nomination julie as ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169</th>\n",
       "      <td>1409</td>\n",
       "      <td>ham</td>\n",
       "      <td>subject industrial worksheets for august activ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5170</th>\n",
       "      <td>4807</td>\n",
       "      <td>spam</td>\n",
       "      <td>subject important online banking alert dear va...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5171 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0 label                                               text  \\\n",
       "0            605   ham  subject enron methanol meter this is a follow ...   \n",
       "1           2349   ham  subject hpl nom for january see attached file ...   \n",
       "2           3624   ham  subject neon retreat ho ho ho we re around to ...   \n",
       "3           4685  spam  subject photoshop windows office cheap main tr...   \n",
       "4           2030   ham  subject re indian springs this deal is to book...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  subject put the on the ft the transport volume...   \n",
       "5167         404   ham  subject and following noms hpl can t take the ...   \n",
       "5168        2933   ham  subject calpine daily gas nomination julie as ...   \n",
       "5169        1409   ham  subject industrial worksheets for august activ...   \n",
       "5170        4807  spam  subject important online banking alert dear va...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "2bfed4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df2.text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "70db576c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171,)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "id": "8614386d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "10046957",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df2.label_num.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "c8deb15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171,)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "id": "65b22a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060e1a70",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "5c4e4a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "c3bc0a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 0.20,random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b2228649",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/Machine_learning/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "nltk.download('stopwords') #Run this command to download and install Stopwords from natural language processor\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "a4cd96bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "054e539d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i,me,my,myself,we,our,ours,ourselves,you,you're,you've,you'll,you'd,your,yours,yourself,yourselves,he,him,his,himself,she,she's,her,hers,herself,it,it's,its,itself,they,them,their,theirs,themselves,what,which,who,whom,this,that,that'll,these,those,am,is,are,was,were,be,been,being,have,has,had,having,do,does,did,doing,a,an,the,and,but,if,or,because,as,until,while,of,at,by,for,with,about,against,between,into,through,during,before,after,above,below,to,from,up,down,in,out,on,off,over,under,again,further,then,once,here,there,when,where,why,how,all,any,both,each,few,more,most,other,some,such,no,nor,not,only,own,same,so,than,too,very,s,t,can,will,just,don,don't,should,should've,now,d,ll,m,o,re,ve,y,ain,aren,aren't,couldn,couldn't,didn,didn't,doesn,doesn't,hadn,hadn't,hasn,hasn't,haven,haven't,isn,isn't,ma,mightn,mightn't,mustn,mustn't,needn,needn't,shan,shan't,shouldn,shouldn't,wasn,wasn't,weren,weren't,won,won't,wouldn,wouldn't,"
     ]
    }
   ],
   "source": [
    "# getting stopwords from nltk \n",
    "for i in list(words):\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "00770095",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no is present\n",
      "not is present\n",
      "don't is present\n",
      "wouldn't is present\n",
      "won't is present\n",
      "wasn't is present\n",
      "isn't is present\n",
      "needn't is present\n",
      "hasn't is present\n"
     ]
    }
   ],
   "source": [
    "#checking if now, no, don't , do not , not are present or not\n",
    "if 'no' in words:\n",
    "    print(\"no is present\")\n",
    "if 'not' in words:\n",
    "    print(\"not is present\")\n",
    "if 'never' in words:\n",
    "    print(\"never is present\")\n",
    "if \"don't\" in words:\n",
    "    print(\"don't is present\")\n",
    "if 'do not' in words:\n",
    "    print(\"do not is present\")\n",
    "if \"din't\" in words:\n",
    "    print(\"din't is present\")\n",
    "if 'did not' in words:\n",
    "    print(\"did not is present\")\n",
    "if \"wouldn't\" in words:\n",
    "    print(\"wouldn't is present\")\n",
    "if 'would not' in words:\n",
    "    print(\"would not is present\")\n",
    "if 'will not' in words:\n",
    "    print(\"will not is present\")\n",
    "if \"won't\" in words:\n",
    "    print(\"won't is present\")\n",
    "if \"wasn't\" in words:\n",
    "    print(\"wasn't is present\")\n",
    "if \"isn't\" in words:\n",
    "    print(\"isn't is present\")\n",
    "if \"needn't\" in words:\n",
    "    print(\"needn't is present\")\n",
    "if \"hasn't\" in words:\n",
    "    print(\"hasn't is present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "c8a7abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removinf all the negative words from the \"words\" variable\n",
    "negative_words = ['no','not','never', \"don't\", \"do not\", \"din't\", \"did not\", \"wouldn't\", \"would not\"]\n",
    "if 'no' in words:\n",
    "    words.remove(\"no\")\n",
    "if 'not' in words:\n",
    "    words.remove(\"not\")\n",
    "if 'never' in words:\n",
    "    words.remove(\"never\")\n",
    "if \"don't\" in words:\n",
    "    words.remove(\"don't\")\n",
    "if 'do not' in words:\n",
    "    words.remove(\"do not\")\n",
    "if \"din't\" in words:\n",
    "    words.remove(\"din't\")\n",
    "if 'did not' in words:\n",
    "    words.remove(\"did not\")\n",
    "if \"wouldn't\" in words:\n",
    "    words.remove(\"wouldn't\")\n",
    "if 'would not' in words:\n",
    "    words.remove(\"would not\")\n",
    "if 'will not' in words:\n",
    "    words.remove(\"will not\")\n",
    "if \"won't\" in words:\n",
    "    words.remove(\"won't\")\n",
    "if \"wasn't\" in words:\n",
    "    words.remove(\"wasn't\")\n",
    "if \"isn't\" in words:\n",
    "    words.remove(\"isn't\")\n",
    "if \"needn't\" in words:\n",
    "    words.remove(\"needn't\")\n",
    "if \"hasn't\" in words:\n",
    "    words.remove(\"hasn't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "e3745f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no negative words are present\n"
     ]
    }
   ],
   "source": [
    "#again rechecking if negative words are present or not \n",
    "negative_words = ['no','not','never', \"don't\", \"do not\", \"din't\", \"did not\", \"wouldn't\", \"would not\"]\n",
    "if 'no' in words:\n",
    "    print(\"no is present\")\n",
    "if 'not' in words:\n",
    "    print(\"not is present\")\n",
    "if 'never' in words:\n",
    "    print(\"never is present\")\n",
    "if \"don't\" in words:\n",
    "    print(\"don't is present\")\n",
    "if 'do not' in words:\n",
    "    print(\"do not is present\")\n",
    "if \"din't\" in words:\n",
    "    print(\"din't is present\")\n",
    "if 'did not' in words:\n",
    "    print(\"did not is present\")\n",
    "if \"wouldn't\" in words:\n",
    "    print(\"wouldn't is present\")\n",
    "if 'would not' in words:\n",
    "    print(\"would not is present\")\n",
    "if 'will not' in words:\n",
    "    print(\"will not is present\")\n",
    "if \"won't\" in words:\n",
    "    print(\"won't is present\")\n",
    "if \"wasn't\" in words:\n",
    "    print(\"wasn't is present\")\n",
    "if \"isn't\" in words:\n",
    "    print(\"isn't is present\")\n",
    "if \"needn't\" in words:\n",
    "    print(\"needn't is present\")\n",
    "if \"hasn't\" in words:\n",
    "    print(\"hasn't is present\")\n",
    "else:\n",
    "    print(\"no negative words are present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "6dfc861c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=words) #initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "2e8774f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = count_vectorizer.fit_transform(xtrain)\n",
    "cv_test = count_vectorizer.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "cd8198ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4136, 39211)"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "726a33f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "e9fd53ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1035, 39211)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "7e29c32b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679c00a4",
   "metadata": {},
   "source": [
    "## Now we can apply Naive Bayes Algotitem Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "b99dd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "1f29dedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB() #initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "864d40dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(cv_train,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9ff2c4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = nb.score(cv_test,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "cd517e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9748792270531401\n"
     ]
    }
   ],
   "source": [
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "ae7153eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(cv_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "a1b3ccd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"Congractulations you have won $1000 please click here to visit our website to claim rewards\", \n",
    "        \"Hey man when are you going to arrive\", \n",
    "        \"Call me when you are free...It's urgent\", \n",
    "        \"It was a good meal...Thankyou. I hope we can go out again sometimes\",\n",
    "       \"Your account is at risk!!!!...please contact admin for more information\", \n",
    "        \"Did you know that you can save a ton of money by downloading this application....click here to know more\",\n",
    "       \"Thanks man you'r a life saver ....Thank you so much\", \n",
    "        \"Are you sufferring from diebaties...Try this 5 ways to control your blood sugar level\",\n",
    "       \"Dude are you free ....Can I call you now\",\n",
    "       \"Your IRS tax refund is pending must accept within 24 hours\",\n",
    "       \"Your mobile recharge will end soon please recharge you mobile to continue services\",\n",
    "       \"Hey mom I will reach home by tommorow 10 AM\"]\n",
    "clean_data = []\n",
    "for k in test:\n",
    "    clean_data.append(clean(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "e71074e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_test1 = count_vectorizer.transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "44556da2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1])"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(cv_test1) # 0 means ham review and 1 means spam review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "71189c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Thanks man you'r a life saver ....Thank you so much\" should be 0 but it's giving 1\n",
    "# \" Your account is at risk!!!!...please contact admin for more information\" should be 1 but it's giving 0\n",
    "# \"Hey mom I will reach home by tommorow 10 AM\" should be 0 but it's giving 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e957161c",
   "metadata": {},
   "source": [
    "## Example 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14914315",
   "metadata": {},
   "source": [
    "## Now applying Naive Bayes algorithm on Movie reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "c4bf6644",
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMDB_Dataset.csv\n",
    "df3 = pd.read_csv('IMDB_Dataset.csv', sep=',') # define seprator as ,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "2d140810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review sentiment\n",
       "0      One of the other reviewers has mentioned that ...  positive\n",
       "1      A wonderful little production. <br /><br />The...  positive\n",
       "2      I thought this was a wonderful way to spend ti...  positive\n",
       "3      Basically there's a family where a little boy ...  negative\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...  positive\n",
       "...                                                  ...       ...\n",
       "49995  I thought this movie did a down right good job...  positive\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...  negative\n",
       "49997  I am a Catholic taught in parochial elementary...  negative\n",
       "49998  I'm going to have to disagree with the previou...  negative\n",
       "49999  No one expects the Star Trek movies to be high...  negative\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "d5e42b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replacing positive and negative with 1's and 0's\n",
    "df3['sentiment'] = df3.sentiment.map({'positive':1,'negative':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ad930383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>I thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Bad plot, bad dialogue, bad acting, idiotic di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>I am a Catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>I'm going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>No one expects the Star Trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      One of the other reviewers has mentioned that ...          1\n",
       "1      A wonderful little production. <br /><br />The...          1\n",
       "2      I thought this was a wonderful way to spend ti...          1\n",
       "3      Basically there's a family where a little boy ...          0\n",
       "4      Petter Mattei's \"Love in the Time of Money\" is...          1\n",
       "...                                                  ...        ...\n",
       "49995  I thought this movie did a down right good job...          1\n",
       "49996  Bad plot, bad dialogue, bad acting, idiotic di...          0\n",
       "49997  I am a Catholic taught in parochial elementary...          0\n",
       "49998  I'm going to have to disagree with the previou...          0\n",
       "49999  No one expects the Star Trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "96224e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(x):\n",
    "    s = re.sub('<*?>',' ', x) #removes all html tags\n",
    "    \n",
    "    s = re.sub(\"wasn't\", 'was not',s) #removes wasn't to was not\n",
    "    s = re.sub(\"don't\", 'do not',s)\n",
    "    s = re.sub(\"din't\", 'did not',s)\n",
    "    s = re.sub(\"wouldn't\", 'would not',s)\n",
    "    s = re.sub(\"won't\", 'will not',s)\n",
    "    s = re.sub(\"isn't\", 'is not',s)\n",
    "    s = re.sub(\"needn't\", 'need not',s)\n",
    "    s = re.sub(\"hasn't\", 'has not',s)\n",
    "    \n",
    "    s = re.sub('[^A-Za-z]',' ',s) #removes everything else except for a to z and A to Z\n",
    "    s = re.sub('\\s+',' ',s) #removes more than one spaces\n",
    "    s = s.strip() #removes spaces from the beginning and ending of the sentences\n",
    "    return s.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "508207d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['review'] = df3.review.apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "edf5f895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a wonderful little production br br the filmin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>i thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basically there s a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei s love in the time of money is a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>i thought this movie did a down right good job...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>bad plot bad dialogue bad acting idiotic direc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>i am a catholic taught in parochial elementary...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>i m going to have to disagree with the previou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>no one expects the star trek movies to be high...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  sentiment\n",
       "0      one of the other reviewers has mentioned that ...          1\n",
       "1      a wonderful little production br br the filmin...          1\n",
       "2      i thought this was a wonderful way to spend ti...          1\n",
       "3      basically there s a family where a little boy ...          0\n",
       "4      petter mattei s love in the time of money is a...          1\n",
       "...                                                  ...        ...\n",
       "49995  i thought this movie did a down right good job...          1\n",
       "49996  bad plot bad dialogue bad acting idiotic direc...          0\n",
       "49997  i am a catholic taught in parochial elementary...          0\n",
       "49998  i m going to have to disagree with the previou...          0\n",
       "49999  no one expects the star trek movies to be high...          0\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "6ce41c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df3.review.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "ea8f2563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "f02c87f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "9df2e135",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df3.sentiment.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "980994c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "01a3fcfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b93f0b6",
   "metadata": {},
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "8c2cb001",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain,xtest,ytrain,ytest = train_test_split(x,y,test_size = 0.20,random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aed9c5c8",
   "metadata": {},
   "source": [
    "## Now Apply CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d4e937f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "21b5267b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i,me,my,myself,we,our,ours,ourselves,you,you're,you've,you'll,you'd,your,yours,yourself,yourselves,he,him,his,himself,she,she's,her,hers,herself,it,it's,its,itself,they,them,their,theirs,themselves,what,which,who,whom,this,that,that'll,these,those,am,is,are,was,were,be,been,being,have,has,had,having,do,does,did,doing,a,an,the,and,but,if,or,because,as,until,while,of,at,by,for,with,about,against,between,into,through,during,before,after,above,below,to,from,up,down,in,out,on,off,over,under,again,further,then,once,here,there,when,where,why,how,all,any,both,each,few,more,most,other,some,such,no,nor,not,only,own,same,so,than,too,very,s,t,can,will,just,don,don't,should,should've,now,d,ll,m,o,re,ve,y,ain,aren,aren't,couldn,couldn't,didn,didn't,doesn,doesn't,hadn,hadn't,hasn,hasn't,haven,haven't,isn,isn't,ma,mightn,mightn't,mustn,mustn't,needn,needn't,shan,shan't,shouldn,shouldn't,wasn,wasn't,weren,weren't,won,won't,wouldn,wouldn't,"
     ]
    }
   ],
   "source": [
    "# getting stopwords from nltk \n",
    "for i in list(words):\n",
    "    print(i,end=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "id": "92893de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no is present\n",
      "not is present\n",
      "don't is present\n",
      "wouldn't is present\n",
      "won't is present\n",
      "wasn't is present\n",
      "isn't is present\n",
      "needn't is present\n",
      "hasn't is present\n"
     ]
    }
   ],
   "source": [
    "#checking if now, no, don't , do not , not are present or not\n",
    "if 'no' in words:\n",
    "    print(\"no is present\")\n",
    "if 'not' in words:\n",
    "    print(\"not is present\")\n",
    "if 'never' in words:\n",
    "    print(\"never is present\")\n",
    "if \"don't\" in words:\n",
    "    print(\"don't is present\")\n",
    "if 'do not' in words:\n",
    "    print(\"do not is present\")\n",
    "if \"din't\" in words:\n",
    "    print(\"din't is present\")\n",
    "if 'did not' in words:\n",
    "    print(\"did not is present\")\n",
    "if \"wouldn't\" in words:\n",
    "    print(\"wouldn't is present\")\n",
    "if 'would not' in words:\n",
    "    print(\"would not is present\")\n",
    "if 'will not' in words:\n",
    "    print(\"will not is present\")\n",
    "if \"won't\" in words:\n",
    "    print(\"won't is present\")\n",
    "if \"wasn't\" in words:\n",
    "    print(\"wasn't is present\")\n",
    "if \"isn't\" in words:\n",
    "    print(\"isn't is present\")\n",
    "if \"needn't\" in words:\n",
    "    print(\"needn't is present\")\n",
    "if \"hasn't\" in words:\n",
    "    print(\"hasn't is present\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67f0f80",
   "metadata": {},
   "source": [
    "## now we have to make sure that all the negative words are removed from 'words = stopwords.words('english')' before we feed it to 'count_vectorizer = CountVectorizer(stop_words=words)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "49099e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removinf all the negative words from the \"words\" variable\n",
    "negative_words = ['no','not','never', \"don't\", \"do not\", \"din't\", \"did not\", \"wouldn't\", \"would not\"]\n",
    "if 'no' in words:\n",
    "    words.remove(\"no\")\n",
    "if 'not' in words:\n",
    "    words.remove(\"not\")\n",
    "if 'never' in words:\n",
    "    words.remove(\"never\")\n",
    "# if \"don't\" in words:\n",
    "#     words.remove(\"don't\")\n",
    "# if 'do not' in words:\n",
    "#     words.remove(\"do not\")\n",
    "# if \"din't\" in words:\n",
    "#     words.remove(\"din't\")\n",
    "# if 'did not' in words:\n",
    "#     words.remove(\"did not\")\n",
    "# if \"wouldn't\" in words:\n",
    "#     words.remove(\"wouldn't\")\n",
    "# if 'would not' in words:\n",
    "#     words.remove(\"would not\")\n",
    "# if 'will not' in words:\n",
    "#     words.remove(\"will not\")\n",
    "# if \"won't\" in words:\n",
    "#     words.remove(\"won't\")\n",
    "# if \"wasn't\" in words:\n",
    "#     words.remove(\"wasn't\")\n",
    "# if \"isn't\" in words:\n",
    "#     words.remove(\"isn't\")\n",
    "# if \"needn't\" in words:\n",
    "#     words.remove(\"needn't\")\n",
    "# if \"hasn't\" in words:\n",
    "#     words.remove(\"hasn't\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "id": "5c2fc673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "don't is present\n",
      "wouldn't is present\n",
      "won't is present\n",
      "wasn't is present\n",
      "isn't is present\n",
      "needn't is present\n",
      "hasn't is present\n"
     ]
    }
   ],
   "source": [
    "#again rechecking if negative words are present or not \n",
    "negative_words = ['no','not','never', \"don't\", \"do not\", \"din't\", \"did not\", \"wouldn't\", \"would not\"]\n",
    "if 'no' in words:\n",
    "    print(\"no is present\")\n",
    "if 'not' in words:\n",
    "    print(\"not is present\")\n",
    "if 'never' in words:\n",
    "    print(\"never is present\")\n",
    "if \"don't\" in words:\n",
    "    print(\"don't is present\")\n",
    "if 'do not' in words:\n",
    "    print(\"do not is present\")\n",
    "if \"din't\" in words:\n",
    "    print(\"din't is present\")\n",
    "if 'did not' in words:\n",
    "    print(\"did not is present\")\n",
    "if \"wouldn't\" in words:\n",
    "    print(\"wouldn't is present\")\n",
    "if 'would not' in words:\n",
    "    print(\"would not is present\")\n",
    "if 'will not' in words:\n",
    "    print(\"will not is present\")\n",
    "if \"won't\" in words:\n",
    "    print(\"won't is present\")\n",
    "if \"wasn't\" in words:\n",
    "    print(\"wasn't is present\")\n",
    "if \"isn't\" in words:\n",
    "    print(\"isn't is present\")\n",
    "if \"needn't\" in words:\n",
    "    print(\"needn't is present\")\n",
    "if \"hasn't\" in words:\n",
    "    print(\"hasn't is present\")\n",
    "else:\n",
    "    print(\"no negative words are present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "2f0e7894",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer(stop_words=words) #initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "ddd06b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_train = count_vectorizer.fit_transform(xtrain) # transforming data from text to integers\n",
    "cv_test = count_vectorizer.transform(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "85d280f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 90496)"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "ea574b32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_train.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "0ec18bdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 90496)"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "26c89a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_test.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d169814",
   "metadata": {},
   "source": [
    "## Now we can apply Naive Bayes Algotitem Machine Learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "098858fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "f6847aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb = MultinomialNB() #initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "f8b2b1e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(cv_train,ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "59d5002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = nb.score(cv_test,ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "a9338a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8552\n"
     ]
    }
   ],
   "source": [
    "print(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "6eacdc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = [\"The first 2 episodes are good enough to hook you up\", \n",
    "        \"I was cringed away from the movie\", \n",
    "        \"The series could have been good. It's disappointing\", \n",
    "        \"Why did I watch this...\",\n",
    "       \"The movie was excellent ....Amazing story Loved it\", \n",
    "        \"The movie was hilariously bad\",\n",
    "          ]\n",
    "clean_data = []\n",
    "for k in test:\n",
    "    clean_data.append(clean(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "4b759328",
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = count_vectorizer.transform(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "07982feb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.predict(test1) # 0 means negative review and 1 means positive review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "f2719297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"The movie was cringy\" should have been 0 but its detecting 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db821f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow] *",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
